{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Whats is HyperLogLog (HLL)\n",
    "\n",
    "A brief introduction is needed to define the purpose and reason for the HLL algorithm properly. First, we briefly present a definition of the following essential terminologies:\n",
    "- multiset and its multiplicity\n",
    "- data stream and source\n",
    "- the purpose of the HLL algorithm on a multiset\n",
    "\n",
    "A set is basically a collection of well-defined objects. We refer to these objects as members or elements of the set. A multiset, on the other hand, is a collection of multiple unordered items or elements. Thus, a multiset could be thought of as a set with the possibility of repeated elements.\n",
    "\n",
    "The multiplicity of an element x in a multiset is the number of times that element appears in the set. In other words, each element of a multiset may have a multiplicity of more than one (1). Thus, the elements of a multiset may be repeated or not. For instance, in the multiset {3, 3, 4, 5, 6} element 3 has multiplicity 2. The elements 4, 5, and 6 all have multiplicities of 1. Order doesn’t matter, so {3, 3, 4, 5, 6} is the same as {3, 4, 6, 5, 3}.\n",
    "\n",
    "Data collected in real life could be of finite cardinality, where the total number of elements in the dataset are known, or infinite cardinality, where the cardinality of the dataset is not known. \n",
    "\n",
    "A data stream is a countably infinite sequence of elements used to represent data elements that are made available over time. Examples are readings from sensors, financial transaction logs, or network data in computer monitoring applications (activity logs from web browsers, IP addresses). Data presented in this fashion is referred to as data stream.\n",
    "\n",
    "Most often, a count of the total number of distinct elements for a stream of data is needed to aid analysis and inform decisions. Literature reveals proposed algorithms that are well efficient for counting distinct values in small datasets. Unfortunately, for very large datasets, these algorithms fail or report incorrect values with high intolerable errors. In addition, calculating the exact cardinality of unique elements in a multiset/data stream requires an amount of memory proportional to the cardinality of the multiset/data stream, which is impractical in real life. \n",
    "\n",
    "For these reasons, the HLL algorithm was proposed to primarily approximate the number of distinct elements in a very large multiset or data stream. The HLL is a probabilistic cardinality estimator, use significantly less memory to obtain an approximation of the cardinality. The HyperLogLog algorithm is able to estimate cardinalities of > 10**9 with a typical accuracy (standard error) of 2%, using 1.5 kB of memory. HyperLogLog is an extension of the earlier LogLog algorithm, itself deriving from the 1984 Flajolet–Martin algorithm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How does the HLL work\n",
    "\n",
    "This presentation makes a slight modification to the original algorithm to include bias and range corrections which help significantly with the results and provide a better description of the algorithm than the one in the lecture slides.\n",
    "\n",
    "~to be continued.... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "alg# Libraries/Modules Employed\n",
    "\n",
    "- numpy\n",
    "- random \n",
    "- math\n",
    "- hashlib\n",
    "- statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = BaseAlg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'001011111011101111010011'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.hashString(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.initialise_registers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random \n",
    "import math\n",
    "import hashlib\n",
    "import statistics\n",
    "\n",
    "\n",
    "class BaseAlg:\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initializes the variables for implementation in base class.\n",
    "        \n",
    "        Sets:\n",
    "            self.registers - the struct to hold all counts\n",
    "            self.k - number of bits of the struct/register to consider\n",
    "            self.m - actual struct size or cardinality.\n",
    "            self.error_rate - error rate\n",
    "            self.results - final estimation\n",
    "        \"\"\"\n",
    "        self.registers = None\n",
    "        self.k = None\n",
    "        self.m = None\n",
    "        self.error_rate = None\n",
    "        self.results = None\n",
    "        \n",
    "\n",
    "    def hashString(self, value_to_hash):\n",
    "        \"\"\"\n",
    "        Hashes the input using the sha1 standard algorithm and returns a \n",
    "        string of binary characters (0, 1) with fixed length (24)\n",
    "        \n",
    "        Args:\n",
    "            value_to_hash [str,int] - represents the value to hash.\n",
    "        Returns:\n",
    "            padded_binary [str] - a hashed string of binary characters (0, 1)\n",
    "            with fixed length (24)\n",
    "            \n",
    "        Example\n",
    "            >> self.hashString(25)\n",
    "            >> '011001000000010000000000'\n",
    "            >> len(self.hashString(25))\n",
    "            >> 24\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        if not isinstance(value_to_hash, str):\n",
    "            value_to_hash = str(value_to_hash) # required by the encoding function\n",
    "        \n",
    "        hashcode=hashlib.sha1(value_to_hash.encode('utf-8')).hexdigest()\n",
    "        bin_code = bin(int(hashcode, 16))[-24:].zfill(24) # output padded to 24 bit string\n",
    "        return bin_code\n",
    "\n",
    "    \n",
    "    def initialise_registers(self):\n",
    "        \"\"\"\n",
    "        Creates the required register for algorithm implementation with all\n",
    "        of the registers initialized as 0. Number of registers are determined\n",
    "        based on error_rate (if defined) else uses the default m = 2**k.\n",
    "\n",
    "        The lower the error_rate, the higher the amount of space or register \n",
    "        size needed which results on higher the precision to actual count.\n",
    "\n",
    "        Sets:\n",
    "            self.m - the actual size of the struct/register\n",
    "            self.registers - container/struct to hold the register of zeros in each bit position of the struct.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.k = 4 # used to calculate default m if error not set\n",
    "        self.error_rate = 0.01 # None, 0.1, 0.01, 0.001 change to see effects\n",
    "\n",
    "        if self.error_rate is not None:\n",
    "            self.m = (1.04/self.error_rate)**2\n",
    "            self.k = math.ceil(math.log(self.m, 2))\n",
    "        \n",
    "        self.m = 2**self.k # actual struct size computation\n",
    "        self.registers = {r: 0 for r in range(self.m)}  # initialize the registers with 0\n",
    "    \n",
    "\n",
    "    def alg(self):\n",
    "        \"\"\"\n",
    "        Main register implementation that updates the count of unique elements in the stream.\n",
    "        ensures for all datastream elements, the register is rightly updated (reason for one-time run)\n",
    "\n",
    "        Updates:\n",
    "            self.register - updates the register to for approximation\n",
    "        \"\"\"\n",
    "        \n",
    "        # ensure initializer is called once \n",
    "        if not self.init:\n",
    "            self.initialise_registers()\n",
    "            self.init = True\n",
    "\n",
    "        \n",
    "        x_hashed = self.hashString(self.x) # obtains the hash of x based on the hashString function\n",
    "        key = int(x_hashed[:self.k], 2)  # extracts first k bits of x_hashed as key\n",
    "        q = x_hashed[self.k:] # obtains the last len(x_hashed)-k bitstring of x_hashed \n",
    "\n",
    "        \n",
    "        if q.find('1') == -1:\n",
    "            value_count = 1\n",
    "        else:\n",
    "            value_count = q.find('1') + 1\n",
    "        if value_count > self.registers[key]:\n",
    "            self.registers[key] = value_count\n",
    "\n",
    "\n",
    "\n",
    "    def range_correction_results(self):\n",
    "        \"\"\"\n",
    "        HLL++ range correction implemented in this module\n",
    "        \"\"\"\n",
    "        \n",
    "        v = [x for x in self.registers.values() if x is not None]\n",
    "        v = [2**x for x in self.registers.values()]\n",
    "\n",
    "        print(\"%d/%d registers holding some count\" % (len(v), self.m))\n",
    "\n",
    "        z = statistics.harmonic_mean(v)\n",
    "        \n",
    "        alfa_dict = {16: 0.673, 32: 0.697, 64: 0.709, 128: 0.7213/(1+(1.079/self.m))}\n",
    "        alfa = alfa_dict[128]\n",
    "\n",
    "        raw = alfa*self.m*z\n",
    "\n",
    "        if raw <= 2.5*self.m:\n",
    "            print(\"Small range correction\")\n",
    "            u = len([x for x in self.registers.values() if x==0])\n",
    "            if u != 0:\n",
    "                self.results = self.m*math.log(self.m/u)\n",
    "            else:\n",
    "                self.results =  raw\n",
    "                \n",
    "        elif raw <= (1/30)*2**32:\n",
    "            print(\"Intermediate range correction\")\n",
    "            self.results = raw\n",
    "            \n",
    "        else:\n",
    "            print(\"Large range correction\")\n",
    "            self.results = -(2**32)*math.log(1-raw/(2**32))\n",
    "        \n",
    "        print(self.results)\n",
    "        return 0\n",
    "\n",
    "\n",
    "    def verify(self):\n",
    "        \"\"\"\n",
    "        computes the exact results using a deterministic algorithm.\n",
    "        computation is solely for comparison with the approximated value\n",
    "        \"\"\"\n",
    "        \n",
    "        print(f\"Actual distinct values: {len(set(self.stream))}\")\n",
    "        print(f\"Total stream values: {len(self.stream)}\")\n",
    "\n",
    "\n",
    "class StreamAlg(BaseAlg):\n",
    "    def __init__(self, stream):\n",
    "        self.stream = stream\n",
    "        self.init = False\n",
    "        \n",
    "\n",
    "    def exec(self):\n",
    "        \"\"\"\n",
    "        Passes each value of the data stream to the alg function for register update. \n",
    "        \"\"\"\n",
    "        for v in self.stream:\n",
    "            self.x = v\n",
    "            self.alg()\n",
    "        self.range_correction_results()\n",
    "        print(f\"Estimated distinct values: {self.results}   ≡   {int(self.results)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "stream = list(range(1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16384/16384 registers holding some count\n",
      "Small range correction\n",
      "992.4613239861708\n",
      "Estimated distinct values: 992.4613239861708   ≡   992\n"
     ]
    }
   ],
   "source": [
    "alg = StreamAlg(stream)\n",
    "alg.exec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual distinct values: 1000\n",
      "Total stream values: 1000\n"
     ]
    }
   ],
   "source": [
    "alg.verify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "statistics.harmonic_mean([1,0,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c11c31f54c6a1524bc46d512b04aae0b7af80f49ff982b19a79f63cf28c4a08a"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
